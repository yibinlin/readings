<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Diffusion Model Study Notes | Yibin Lin's Reading Blog</title>
<meta name=keywords content="misc,diffusion,stable diffusion"><meta name=description content="Basic modules of Stable Diffusion Model Basic tutorial: https://comfyanonymous.github.io/ComfyUI_tutorial_vn/ CLIP: encode text, another name: text encoder Sampler: takes the main Stable Diffusion model as an input, takes both positive and negative prompts encoded by CLIP model + a latent image (can be blank) sampler takes this input latent image, adds noise to it and then denoises it using the main model prompts and negative prompts are passed to model at each sampling step sampler outputs the denoised image VAE: translates an image from latent space to pixel space Prompting: (word:1."><meta name=author content="Yibin Lin"><link rel=canonical href=https://yibinlin.github.io/readings/posts/diffusion_model_study/><link crossorigin=anonymous href=/readings/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://yibinlin.github.io/readings/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://yibinlin.github.io/readings/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://yibinlin.github.io/readings/favicon-32x32.png><link rel=apple-touch-icon href=https://yibinlin.github.io/readings/apple-touch-icon.png><link rel=mask-icon href=https://yibinlin.github.io/readings/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Diffusion Model Study Notes"><meta property="og:description" content="Basic modules of Stable Diffusion Model Basic tutorial: https://comfyanonymous.github.io/ComfyUI_tutorial_vn/ CLIP: encode text, another name: text encoder Sampler: takes the main Stable Diffusion model as an input, takes both positive and negative prompts encoded by CLIP model + a latent image (can be blank) sampler takes this input latent image, adds noise to it and then denoises it using the main model prompts and negative prompts are passed to model at each sampling step sampler outputs the denoised image VAE: translates an image from latent space to pixel space Prompting: (word:1."><meta property="og:type" content="article"><meta property="og:url" content="https://yibinlin.github.io/readings/posts/diffusion_model_study/"><meta property="og:image" content="https://yibinlin.github.io/readings/%3Cimage%20path/url%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-02-10T00:00:00+00:00"><meta property="article:modified_time" content="2024-02-10T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://yibinlin.github.io/readings/%3Cimage%20path/url%3E"><meta name=twitter:title content="Diffusion Model Study Notes"><meta name=twitter:description content="Basic modules of Stable Diffusion Model Basic tutorial: https://comfyanonymous.github.io/ComfyUI_tutorial_vn/ CLIP: encode text, another name: text encoder Sampler: takes the main Stable Diffusion model as an input, takes both positive and negative prompts encoded by CLIP model + a latent image (can be blank) sampler takes this input latent image, adds noise to it and then denoises it using the main model prompts and negative prompts are passed to model at each sampling step sampler outputs the denoised image VAE: translates an image from latent space to pixel space Prompting: (word:1."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://yibinlin.github.io/readings/posts/"},{"@type":"ListItem","position":2,"name":"Diffusion Model Study Notes","item":"https://yibinlin.github.io/readings/posts/diffusion_model_study/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Diffusion Model Study Notes","name":"Diffusion Model Study Notes","description":"Basic modules of Stable Diffusion Model Basic tutorial: https://comfyanonymous.github.io/ComfyUI_tutorial_vn/ CLIP: encode text, another name: text encoder Sampler: takes the main Stable Diffusion model as an input, takes both positive and negative prompts encoded by CLIP model + a latent image (can be blank) sampler takes this input latent image, adds noise to it and then denoises it using the main model prompts and negative prompts are passed to model at each sampling step sampler outputs the denoised image VAE: translates an image from latent space to pixel space Prompting: (word:1.","keywords":["misc","diffusion","stable diffusion"],"articleBody":"Basic modules of Stable Diffusion Model Basic tutorial: https://comfyanonymous.github.io/ComfyUI_tutorial_vn/ CLIP: encode text, another name: text encoder Sampler: takes the main Stable Diffusion model as an input, takes both positive and negative prompts encoded by CLIP model + a latent image (can be blank) sampler takes this input latent image, adds noise to it and then denoises it using the main model prompts and negative prompts are passed to model at each sampling step sampler outputs the denoised image VAE: translates an image from latent space to pixel space Prompting: (word:1.5) means it is 1.5 more effective OpenArt OpenArt sharing workflows: https://openart.ai/workflows/dev Installing ComfyUI ComfyUI on Colab notebook: https://colab.research.google.com/github/comfyanonymous/ComfyUI/blob/master/notebooks/comfyui_colab.ipynb ComfyUI examples: https://github.com/comfyanonymous/ComfyUI_examples/tree/master/2_pass_txt2img ComfyUI installation locally Metal Performance Shaders (MPS) For Mac Metal: https://github.com/comfyanonymous/ComfyUI?tab=readme-ov-file#installing ComfyUI installation from Colab: Uses CloudFlare Reverse Proxy ","wordCount":"130","inLanguage":"en","image":"https://yibinlin.github.io/readings/%3Cimage%20path/url%3E","datePublished":"2024-02-10T00:00:00Z","dateModified":"2024-02-10T00:00:00Z","author":{"@type":"Person","name":"Yibin Lin"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://yibinlin.github.io/readings/posts/diffusion_model_study/"},"publisher":{"@type":"Organization","name":"Yibin Lin's Reading Blog","logo":{"@type":"ImageObject","url":"https://yibinlin.github.io/readings/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://yibinlin.github.io/readings/ accesskey=h title="Yibin Lin's Reading Blog (Alt + H)">Yibin Lin's Reading Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Diffusion Model Study Notes</h1><div class=post-meta><span title='2024-02-10 00:00:00 +0000 UTC'>February 10, 2024</span>&nbsp;Â·&nbsp;Yibin Lin</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#basic-modules-of-stable-diffusion-model aria-label="Basic modules of Stable Diffusion Model">Basic modules of Stable Diffusion Model</a></li><li><a href=#openart aria-label=OpenArt>OpenArt</a></li><li><a href=#installing-comfyui aria-label="Installing ComfyUI">Installing ComfyUI</a></li></ul></div></details></div><div class=post-content><h2 id=basic-modules-of-stable-diffusion-model>Basic modules of Stable Diffusion Model<a hidden class=anchor aria-hidden=true href=#basic-modules-of-stable-diffusion-model>#</a></h2><ol><li>Basic tutorial: <a href=https://comfyanonymous.github.io/ComfyUI_tutorial_vn/>https://comfyanonymous.github.io/ComfyUI_tutorial_vn/</a></li><li>CLIP: encode text, another name: text encoder</li><li>Sampler: takes the main <code>Stable Diffusion</code> model as an input, takes both positive and negative prompts encoded by <code>CLIP</code> model + a latent image (can be blank)<ol><li>sampler takes this input latent image, adds noise to it and then denoises it using the main model</li><li>prompts and negative prompts are passed to model at each sampling step</li><li>sampler outputs the denoised image</li></ol></li><li>VAE: translates an image from latent space to pixel space</li><li>Prompting: <code>(word:1.5)</code> means it is 1.5 more effective</li></ol><h2 id=openart>OpenArt<a hidden class=anchor aria-hidden=true href=#openart>#</a></h2><ul><li>OpenArt sharing workflows: <a href=https://openart.ai/workflows/dev>https://openart.ai/workflows/dev</a></li></ul><h2 id=installing-comfyui>Installing ComfyUI<a hidden class=anchor aria-hidden=true href=#installing-comfyui>#</a></h2><ol><li>ComfyUI on Colab notebook:<ol><li><a href=https://colab.research.google.com/github/comfyanonymous/ComfyUI/blob/master/notebooks/comfyui_colab.ipynb>https://colab.research.google.com/github/comfyanonymous/ComfyUI/blob/master/notebooks/comfyui_colab.ipynb</a></li></ol></li><li>ComfyUI examples: <a href=https://github.com/comfyanonymous/ComfyUI_examples/tree/master/2_pass_txt2img>https://github.com/comfyanonymous/ComfyUI_examples/tree/master/2_pass_txt2img</a></li><li>ComfyUI installation locally<ol><li>Metal Performance Shaders (MPS)</li><li>For Mac Metal: <a href="https://github.com/comfyanonymous/ComfyUI?tab=readme-ov-file#installing">https://github.com/comfyanonymous/ComfyUI?tab=readme-ov-file#installing</a></li></ol></li><li>ComfyUI installation from Colab:<ol><li>Uses <a href=https://github.com/cloudflare/cloudflared>CloudFlare Reverse Proxy</a></li></ol></li></ol></div><footer class=post-footer><ul class=post-tags><li><a href=https://yibinlin.github.io/readings/tags/misc/>misc</a></li><li><a href=https://yibinlin.github.io/readings/tags/diffusion/>diffusion</a></li><li><a href=https://yibinlin.github.io/readings/tags/stable-diffusion/>stable diffusion</a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://yibinlin.github.io/readings/>Yibin Lin's Reading Blog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>